{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F-A1JKUN8El"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymoAxWejN8Ep",
        "outputId": "4f954650-b6f9-4fd7-b505-ada173b63fd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (2.0.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (1.6.1)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.2)\n",
            "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-tabnet\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-tabnet-4.1.0\n"
          ]
        }
      ],
      "source": [
        "%pip install pytorch-tabnet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import torch\n",
        "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYKhvQDaN8Es"
      },
      "source": [
        "# Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoQCEGn1N8Et"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "sample_submission = pd.read_csv('sample_submission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1fPlCiiN8Eu"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvGYpnP0N8Ev",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8463273-74de-4445-c3ba-d7a5f2be8b3c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0cd901f3-b5bd-4ce7-b29a-047b4356be6f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0cd901f3-b5bd-4ce7-b29a-047b4356be6f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.csv to train (6).csv\n",
            "Loaded file: train (6).csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ecfe6acb-29ac-4314-bded-93713b3f04e6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ecfe6acb-29ac-4314-bded-93713b3f04e6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.csv to test (4).csv\n",
            "Loaded file: test (4).csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-45bf21bf1008>:42: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  train[feature] = train[feature].fillna('Missing')\n",
            "<ipython-input-9-45bf21bf1008>:43: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  test[feature] = test[feature].fillna('Missing')\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 51649 (\\N{HANGUL SYLLABLE JIG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 50896 (\\N{HANGUL SYLLABLE WEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 44256 (\\N{HANGUL SYLLABLE GO}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 44061 (\\N{HANGUL SYLLABLE GAEG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 48177 (\\N{HANGUL SYLLABLE BAEG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 47564 (\\N{HANGUL SYLLABLE MAN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 47749 (\\N{HANGUL SYLLABLE MYEONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 52509 (\\N{HANGUL SYLLABLE CONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 53804 (\\N{HANGUL SYLLABLE TU}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 51088 (\\N{HANGUL SYLLABLE JA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 44552 (\\N{HANGUL SYLLABLE GEUM}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 50613 (\\N{HANGUL SYLLABLE EOG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 50672 (\\N{HANGUL SYLLABLE YEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 47588 (\\N{HANGUL SYLLABLE MAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 52636 (\\N{HANGUL SYLLABLE CUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 54036 (\\N{HANGUL SYLLABLE PAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 47196 (\\N{HANGUL SYLLABLE RO}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 50892 (\\N{HANGUL SYLLABLE WEO}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 51064 (\\N{HANGUL SYLLABLE IN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 45817 (\\N{HANGUL SYLLABLE DANG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 45824 (\\N{HANGUL SYLLABLE DAE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 48708 (\\N{HANGUL SYLLABLE BI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 52824 (\\N{HANGUL SYLLABLE CI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 50629 (\\N{HANGUL SYLLABLE EOB}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 50984 (\\N{HANGUL SYLLABLE YUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 51217 (\\N{HANGUL SYLLABLE JEOB}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 51216 (\\N{HANGUL SYLLABLE JEOM}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 49457 (\\N{HANGUL SYLLABLE SEONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 44277 (\\N{HANGUL SYLLABLE GONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 54869 (\\N{HANGUL SYLLABLE HWAG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:61: UserWarning: Glyph 47456 (\\N{HANGUL SYLLABLE RYUL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.draw()\n",
            "<ipython-input-9-45bf21bf1008>:135: UserWarning: Glyph 49457 (\\N{HANGUL SYLLABLE SEONG}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-9-45bf21bf1008>:135: UserWarning: Glyph 44277 (\\N{HANGUL SYLLABLE GONG}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-9-45bf21bf1008>:135: UserWarning: Glyph 54869 (\\N{HANGUL SYLLABLE HWAG}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-9-45bf21bf1008>:135: UserWarning: Glyph 47456 (\\N{HANGUL SYLLABLE RYUL}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-9-45bf21bf1008>:135: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-9-45bf21bf1008>:135: UserWarning: Glyph 54632 (\\N{HANGUL SYLLABLE HAM}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 51649 (\\N{HANGUL SYLLABLE JIG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 50896 (\\N{HANGUL SYLLABLE WEON}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 44256 (\\N{HANGUL SYLLABLE GO}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 44061 (\\N{HANGUL SYLLABLE GAEG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 48177 (\\N{HANGUL SYLLABLE BAEG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 47564 (\\N{HANGUL SYLLABLE MAN}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 47749 (\\N{HANGUL SYLLABLE MYEONG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 52509 (\\N{HANGUL SYLLABLE CONG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 53804 (\\N{HANGUL SYLLABLE TU}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 51088 (\\N{HANGUL SYLLABLE JA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 44552 (\\N{HANGUL SYLLABLE GEUM}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 50613 (\\N{HANGUL SYLLABLE EOG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 50672 (\\N{HANGUL SYLLABLE YEON}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 47588 (\\N{HANGUL SYLLABLE MAE}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 52636 (\\N{HANGUL SYLLABLE CUL}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 54036 (\\N{HANGUL SYLLABLE PAL}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 47196 (\\N{HANGUL SYLLABLE RO}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 50892 (\\N{HANGUL SYLLABLE WEO}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 51064 (\\N{HANGUL SYLLABLE IN}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 45817 (\\N{HANGUL SYLLABLE DANG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 45824 (\\N{HANGUL SYLLABLE DAE}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 48708 (\\N{HANGUL SYLLABLE BI}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 52824 (\\N{HANGUL SYLLABLE CI}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 44592 (\\N{HANGUL SYLLABLE GI}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 50629 (\\N{HANGUL SYLLABLE EOB}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 50984 (\\N{HANGUL SYLLABLE YUL}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 51217 (\\N{HANGUL SYLLABLE JEOB}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 51216 (\\N{HANGUL SYLLABLE JEOM}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 49457 (\\N{HANGUL SYLLABLE SEONG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 44277 (\\N{HANGUL SYLLABLE GONG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 54869 (\\N{HANGUL SYLLABLE HWAG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 47456 (\\N{HANGUL SYLLABLE RYUL}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
            "<ipython-input-9-45bf21bf1008>:136: UserWarning: Glyph 54632 (\\N{HANGUL SYLLABLE HAM}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"Selected_Correlation_Heatmap.png\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "성공확률과의 상관관계 (절댓값 내림차순):\n",
            "기업가치(중간값)          0.043256\n",
            "상장여부               0.031413\n",
            "국가                 0.029570\n",
            "분야                -0.026773\n",
            "직원 1인당 기업가치        0.022197\n",
            "연매출(억원)           -0.018994\n",
            "SNS 팔로워 수(백만명)     0.017927\n",
            "SNS비율              0.017731\n",
            "고객 1인당 SNS 접점 수    0.017731\n",
            "투자금 대비 기업가치       -0.016067\n",
            "투자 대비 가치          -0.016067\n",
            "총 투자금(억원)         -0.014939\n",
            "투자금 대비 매출         -0.014520\n",
            "고객 대비 직원 수 비율      0.014196\n",
            "고객수(백만명)          -0.012123\n",
            "인수여부              -0.012065\n",
            "직원 수              -0.011581\n",
            "고객 1인당 기업가치        0.011152\n",
            "고객 1인당 매출          0.009432\n",
            "직원 1인당 매출          0.008515\n",
            "직원 1인당 투자금        -0.008057\n",
            "투자단계              -0.007835\n",
            "고객 1인당 투자금         0.007661\n",
            "연매출 대비 기업가치       -0.006579\n",
            "설립연도               0.002147\n",
            "투자금 대비 SNS 팔로워     0.001101\n",
            "Name: 성공확률, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import io\n",
        "for filename in uploaded.keys():\n",
        "  train = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "  print(f\"Loaded file: {filename}\")\n",
        "  break\n",
        "\n",
        "train.head()\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "import io\n",
        "for filename in uploaded.keys():\n",
        "  test = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "  print(f\"Loaded file: {filename}\")\n",
        "  break\n",
        "\n",
        "test.head()\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 설립연도 타입 변환, 범주형으로 사용하기 위해 (int -> object)\n",
        "train['설립연도'] =train['설립연도'].astype('object')\n",
        "test['설립연도'] =test['설립연도'].astype('object')\n",
        "\n",
        "category_features = ['설립연도','국가','분야','투자단계']\n",
        "numeric_features = ['직원 수','고객수(백만명)','총 투자금(억원)','연매출(억원)','SNS 팔로워 수(백만명)']\n",
        "bool_features = ['인수여부','상장여부']\n",
        "\n",
        "# LabelEncoder 객체를 각 범주형 feature별로 따로 저장하여 사용\n",
        "encoders = {}\n",
        "\n",
        "# 범주형 데이터를 encoding, 범주형 데이터를 숫자로 변환\n",
        "for feature in category_features:\n",
        "    encoders[feature] = LabelEncoder()\n",
        "    train[feature] = train[feature].fillna('Missing')\n",
        "    test[feature] = test[feature].fillna('Missing')\n",
        "    train[feature] = encoders[feature].fit_transform(train[feature])\n",
        "    test[feature] = encoders[feature].transform(test[feature])\n",
        "\n",
        "# 불리언 값을 0과 1로 변환 ('Yes' → 1, 'No' → 0 으로 변환)\n",
        "bool_map = {'Yes': 1, 'No': 0}\n",
        "\n",
        "for feature in bool_features:\n",
        "    train[feature] = train[feature].map(bool_map)\n",
        "    test[feature] = test[feature].map(bool_map)\n",
        "\n",
        "# 수치형 변수 결측치를 평균값으로 대체\n",
        "for feature in numeric_features:\n",
        "    mean_value = train[feature].mean()\n",
        "    train[feature] = train[feature].fillna(mean_value).infer_objects(copy=False)\n",
        "    test[feature] = test[feature].fillna(mean_value).infer_objects(copy=False)\n",
        "\n",
        "def parse_value_range(value):\n",
        "    if isinstance(value, str) and '-' in value:\n",
        "        low, high = map(float, value.split('-'))\n",
        "        return (low + high) / 2\n",
        "    try:\n",
        "        return float(value)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "# '~이상' 한글 포함 문자열 처리\n",
        "def parse_value_range(value):\n",
        "    try:\n",
        "        return float(value)\n",
        "    except:\n",
        "        if isinstance(value, str) and '이상' in value:\n",
        "          return float(value.replace('이상', '').strip())\n",
        "        return np.nan\n",
        "\n",
        "# 기업가치를 중간값으로 변환\n",
        "train['기업가치(중간값)'] = train['기업가치(백억원)'].apply(parse_value_range)\n",
        "test['기업가치(중간값)'] = test['기업가치(백억원)'].apply(parse_value_range)\n",
        "\n",
        "# 수치형 변수 ; 파생 변수 생성\n",
        "def create_derived_features(df):\n",
        "  df = df.copy()\n",
        "  df['직원 1인당 매출'] = df['연매출(억원)'] / df['직원 수']\n",
        "  df['고객 1인당 매출'] = df['연매출(억원)'] / df['고객수(백만명)']\n",
        "  df['고객 1인당 투자금'] = df['총 투자금(억원)'] / df['고객수(백만명)']\n",
        "  df['투자 대비 가치'] = df['기업가치(중간값)'] / df['총 투자금(억원)']\n",
        "  df['직원 1인당 기업가치'] = df['기업가치(중간값)'] / df['직원 수']\n",
        "  df['투자금 대비 매출'] = df['연매출(억원)'] / df['총 투자금(억원)']\n",
        "  df['SNS비율'] = df['SNS 팔로워 수(백만명)'] / df['고객수(백만명)']\n",
        "  df['직원 1인당 투자금'] = df['총 투자금(억원)'] / df['직원 수']\n",
        "  df['고객 1인당 기업가치'] = df['기업가치(중간값)'] / df['고객수(백만명)']\n",
        "  df['고객 1인당 SNS 접점 수'] = df['SNS 팔로워 수(백만명)'] / df['고객수(백만명)']\n",
        "  df['고객 대비 직원 수 비율'] = df['직원 수'] / df['고객수(백만명)']\n",
        "  df['투자금 대비 SNS 팔로워'] = df['SNS 팔로워 수(백만명)'] / df['총 투자금(억원)']\n",
        "  df['연매출 대비 기업가치'] = df['기업가치(중간값)'] / df['연매출(억원)']\n",
        "  df['투자금 대비 기업가치'] = df['기업가치(중간값)'] / df['총 투자금(억원)']\n",
        "\n",
        "  df.fillna(0, inplace=True) # NaN 값은 0 또는 다른 기준으로 대체\n",
        "  return df\n",
        "\n",
        "# train/test 데이터에 위 파생 변수들을 실제로 적용\n",
        "train = create_derived_features(train)\n",
        "test = create_derived_features(test)\n",
        "\n",
        "\n",
        "# 상관관계 분석 코드\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(2023)\n",
        "\n",
        "# 새로운 변수로, 계산할 변수 선택\n",
        "selected_vars = [\n",
        "    '직원 수', '고객수(백만명)', '총 투자금(억원)', '연매출(억원)', 'SNS 팔로워 수(백만명)',\n",
        "    '직원 1인당 매출', '고객 1인당 매출', '고객 1인당 투자금', '투자 대비 가치',\n",
        "    '직원 1인당 기업가치', '투자금 대비 매출', 'SNS비율', '직원 1인당 투자금',\n",
        "    '고객 1인당 기업가치', '고객 1인당 SNS 접점 수', '고객 대비 직원 수 비율',\n",
        "    '투자금 대비 SNS 팔로워', '연매출 대비 기업가치', '투자금 대비 기업가치', '성공확률'\n",
        "]\n",
        "\n",
        "df_selected = train[selected_vars]\n",
        "correlation_matrix = df_selected.corr()\n",
        "\n",
        "# 상관관계를 절댓값 기준 내림차순 정렬\n",
        "target_corr = correlation_matrix['성공확률'].drop('성공확률')\n",
        "target_corr_sorted = target_corr.reindex(target_corr.abs().sort_values(ascending=False).index)\n",
        "\n",
        "# (히트맵으로 시각화?)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
        "plt.title('Correlation Matrix with 성공확률 포함')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"Selected_Correlation_Heatmap.png\")\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# 상관관계 출력 코드\n",
        "df = train.copy()\n",
        "\n",
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "correlation_with_success = numeric_df.corr()['성공확률'].drop('성공확률')\n",
        "\n",
        "# 수치형 변수와 성공확률 간 상관관계 계산\n",
        "correlation_with_success_sorted = correlation_with_success.reindex(\n",
        "    correlation_with_success.abs().sort_values(ascending=False).index\n",
        ")\n",
        "\n",
        "print(\"성공확률과의 상관관계 (절댓값 내림차순):\")\n",
        "print(correlation_with_success_sorted)\n",
        "\n",
        "#특성과 타겟 변수 분리\n",
        "train = train.drop(columns=['ID'], axis = 1)\n",
        "test = test.drop(columns=['ID'], axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iduHl8GxN8Ex"
      },
      "source": [
        "# K-Fold Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YpskKPCN8Ey",
        "outputId": "6b4c39a4-e707-4586-c34f-f00e807ffe50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔁 Fold 1/5\n",
            "▶ Pretraining...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶ Fine-tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
            "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_mae = 0.20616\n",
            "\n",
            "🔁 Fold 2/5\n",
            "▶ Pretraining...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶ Fine-tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
            "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_mae = 0.20969\n",
            "\n",
            "🔁 Fold 3/5\n",
            "▶ Pretraining...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶ Fine-tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
            "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_mae = 0.20149\n",
            "\n",
            "🔁 Fold 4/5\n",
            "▶ Pretraining...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶ Fine-tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
            "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_mae = 0.20984\n",
            "\n",
            "🔁 Fold 5/5\n",
            "▶ Pretraining...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶ Fine-tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:248: UserWarning: Loading weights from unsupervised pretraining\n",
            "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_mae = 0.20543\n",
            "\n",
            "✅ 모든 fold 모델 학습 완료!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ],
      "source": [
        "# 타겟 지정\n",
        "target = train['성공확률']\n",
        "X = train[features]\n",
        "y = target\n",
        "\n",
        "# KFold 설정\n",
        "N_FOLDS = 5\n",
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "models = [] # 모델 저장 리스트\n",
        "cv_scores = []\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
        "    print(f\"\\n🔁 Fold {fold+1}/{N_FOLDS}\")\n",
        "\n",
        "    X_train = X.iloc[train_idx].values\n",
        "    y_train = y.iloc[train_idx].values.reshape(-1, 1)\n",
        "\n",
        "    X_valid = X.iloc[valid_idx].values\n",
        "    y_valid = y.iloc[valid_idx].values.reshape(-1, 1)\n",
        "\n",
        "    # 비지도 사전학습\n",
        "    print(\"▶ Pretraining...\")\n",
        "\n",
        "    pretrainer = TabNetPretrainer(\n",
        "        cat_idxs=cat_idxs,\n",
        "        cat_dims=cat_dims,\n",
        "        seed=42,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    pretrainer.fit(\n",
        "        X_train=X_train,\n",
        "        max_epochs=100,\n",
        "        batch_size=512,\n",
        "        virtual_batch_size=64\n",
        "    )\n",
        "\n",
        "    # 지도 학습\n",
        "    print(\"▶ Fine-tuning...\")\n",
        "    model = TabNetRegressor(\n",
        "        cat_idxs=cat_idxs,\n",
        "        cat_dims=cat_dims,\n",
        "        seed=42,\n",
        "        verbose=0,\n",
        "        optimizer_fn=torch.optim.AdamW\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train=X_train, y_train=y_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        from_unsupervised=pretrainer,\n",
        "        eval_metric=['mae'],\n",
        "        max_epochs=100,\n",
        "        patience=10\n",
        "    )\n",
        "\n",
        "    # 모델을 메모리에 저장\n",
        "    models.append(model)\n",
        "    cv_scores.append(model.best_cost)\n",
        "\n",
        "print(\"\\n✅ 모든 fold 모델 학습 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TeYJFg1N8E0"
      },
      "source": [
        "# K-Fold Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf6xyWfnN8E1",
        "outputId": "ab589fe2-a761-4e23-dd92-afd54a51c446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict with fold 1\n",
            "Predict with fold 2\n",
            "Predict with fold 3\n",
            "Predict with fold 4\n",
            "Predict with fold 5\n"
          ]
        }
      ],
      "source": [
        "# 저장된 모델들로 예측\n",
        "predictions_list = []\n",
        "\n",
        "for fold, model in enumerate(models):\n",
        "    print(f\"Predict with fold {fold+1}\")\n",
        "    preds = model.predict(test[features].values)\n",
        "    predictions_list.append(preds)\n",
        "\n",
        "# 평균 예측\n",
        "final_predictions = np.mean(predictions_list, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFcUyIykN8E2"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7TT8mcvN8E2"
      },
      "outputs": [],
      "source": [
        "sample_submission['성공확률'] = final_predictions\n",
        "sample_submission.to_csv('./baseline_submission.csv', index = False, encoding = 'utf-8-sig')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "seohee3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}